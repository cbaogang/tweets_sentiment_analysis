{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32a183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# pd.options.display.max_colwidth = 100\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a93e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_tweet.csv\",encoding='latin1')\n",
    "test = pd.read_csv(\"data/test_tweet.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa6977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserName          int64\n",
      "ScreenName        int64\n",
      "Location         object\n",
      "TweetAt          object\n",
      "OriginalTweet    object\n",
      "Sentiment        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_types = train.dtypes\n",
    "\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6545f861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet',\n",
       "       'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6281caf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName         0\n",
       "ScreenName       0\n",
       "Location         0\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94636073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName         0\n",
       "ScreenName       0\n",
       "Location         0\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1c53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=[\"Location\"])\n",
    "test = test.dropna(subset=[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523a9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tldextract\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs, HTML tags, square brackets, backslashes\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text)\n",
    "    \n",
    "    # Remove punctuations, numbers, and newlines\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "   # Perform stemming using Snowball Stemmer\n",
    "   # stemmer = SnowballStemmer('english')\n",
    "   # stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2fcf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['OriginalTweet']  = train['OriginalTweet'].apply(preprocess_text)\n",
    "test['OriginalTweet']  = test['OriginalTweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d2bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_location(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove non-alphanumeric characters, numbers, and extra spaces\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        cleaned_text = re.sub(r'\\d+', '', cleaned_text)\n",
    "        cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text)\n",
    "        return cleaned_text.strip()\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9fe7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Location'] = train['Location'].apply(clean_location)\n",
    "test['Location'] = test['Location'].apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06cb32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty strings\n",
    "train = train[train['Location'] != '']\n",
    "train = train[train['OriginalTweet'] != '']\n",
    "\n",
    "test = test[test['Location'] != '']\n",
    "test = test[test['OriginalTweet'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1e12b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef label_preprocessing(df):\\n    lab_dict={\\n        'Extremely Negative': 'negative',\\n        'Negative': 'negative',\\n        'Neutral': 'neutral',\\n        'Positive': 'positive',\\n        'Extremely Positive': 'positive'\\n    }\\n    df['Sentiment']=df['Sentiment'].map(lab_dict)\\n    \\n    encoder={'negative': -1, 'neutral': 0, 'positive': 1}\\n    df['Sentiment']=df['Sentiment'].map(encoder)\\n    \\n    return df\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def label_preprocessing(df):\n",
    "    lab_dict={\n",
    "        'Extremely Negative': 'negative',\n",
    "        'Negative': 'negative',\n",
    "        'Neutral': 'neutral',\n",
    "        'Positive': 'positive',\n",
    "        'Extremely Positive': 'positive'\n",
    "    }\n",
    "    df['Sentiment']=df['Sentiment'].map(lab_dict)\n",
    "    \n",
    "    encoder={'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "    df['Sentiment']=df['Sentiment'].map(encoder)\n",
    "    \n",
    "    return df\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79aec30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths give elderly ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>T</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>news region first confirmed covid case came su...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>supermarket today buy toilet paper</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>due covid retail store classroom atlanta open ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName        Location     TweetAt  \\\n",
       "1      3800       48752              UK  16-03-2020   \n",
       "2      3801       48753       Vagabonds  16-03-2020   \n",
       "3      3804       48756               T  16-03-2020   \n",
       "4      3806       48758         Austria  16-03-2020   \n",
       "5      3807       48759  Atlanta GA USA  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "1  advice talk neighbours family exchange phone n...  Positive  \n",
       "2  coronavirus australia woolworths give elderly ...  Positive  \n",
       "3  news region first confirmed covid case came su...  Positive  \n",
       "4                 supermarket today buy toilet paper   Neutral  \n",
       "5  due covid retail store classroom atlanta open ...  Positive  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d8c637e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = preprocessing(test)\n",
    "# test = label_preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e64c4260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName         0\n",
       "ScreenName       0\n",
       "Location         0\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4efd6877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName         0\n",
       "ScreenName       0\n",
       "Location         0\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a173f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_tweet.csv\", index=False)\n",
    "test.to_csv(\"test_tweet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe053ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.concat([train, test])\n",
    "tweet_data.to_csv(\"tweet_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f4539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
